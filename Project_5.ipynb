{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNAiqgRJhkfNPSrjIw8pdR0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jasp27/ds4bme_intro_p1/blob/main/Project_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Fit a pytorch model to the oasis data that treats gold lesions as the outcome and T2 value as the predictor. Use a bias term, sigmoid output activation function and no hidden layers. Do not split the data into a testing and training dataset. Demonstrate that the fitted values are the same as those obtained with logistic regression.\n",
        "\n"
      ],
      "metadata": {
        "id": "OGwFZUjQ03CK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NvQEVMft0x3x"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import statsmodels.formula.api as smf\n",
        "import statsmodels as sm\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "## Read in the data and display a few rows\n",
        "dat = pd.read_csv(\"https://raw.githubusercontent.com/bcaffo/ds4bme_intro/master/data/oasis.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Create a binary outcome variable \n",
        "dat = dat.assign(y = dat.GOLD_Lesions)\n",
        "## Create a normalized regression variable\n",
        "dat = dat.assign(x = (dat.T2 - np.mean(dat.T2)) / np.std(dat.T2))\n",
        "dat.head()"
      ],
      "metadata": {
        "id": "qQrYaZOJE1fp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "90699429-e198-4b7a-be49-ca0f0c491776"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      FLAIR        PD        T1        T2  FLAIR_10     PD_10     T1_10  \\\n",
              "0  1.143692  1.586219 -0.799859  1.634467  0.437568  0.823800 -0.002059   \n",
              "1  1.652552  1.766672 -1.250992  0.921230  0.663037  0.880250 -0.422060   \n",
              "2  1.036099  0.262042 -0.858565 -0.058211 -0.044280 -0.308569  0.014766   \n",
              "3  1.037692  0.011104 -1.228796 -0.470222 -0.013971 -0.000498 -0.395575   \n",
              "4  1.580589  1.730152 -0.860949  1.245609  0.617957  0.866352 -0.099919   \n",
              "\n",
              "      T2_10  FLAIR_20     PD_20     T1_20     T2_20  GOLD_Lesions  y         x  \n",
              "0  0.573663  0.279832  0.548341  0.219136  0.298662             0  0  1.466353  \n",
              "1  0.542597  0.422182  0.549711  0.061573  0.280972             0  0  0.534121  \n",
              "2 -0.256075 -0.136532 -0.350905  0.020673 -0.259914             0  0 -0.746050  \n",
              "3 -0.221900  0.000807 -0.003085 -0.193249 -0.139284             0  0 -1.284565  \n",
              "4  0.384261  0.391133  0.608826  0.071648  0.340601             0  0  0.958099  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-494f9b53-9de2-460f-a737-ed74bc1716ca\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FLAIR</th>\n",
              "      <th>PD</th>\n",
              "      <th>T1</th>\n",
              "      <th>T2</th>\n",
              "      <th>FLAIR_10</th>\n",
              "      <th>PD_10</th>\n",
              "      <th>T1_10</th>\n",
              "      <th>T2_10</th>\n",
              "      <th>FLAIR_20</th>\n",
              "      <th>PD_20</th>\n",
              "      <th>T1_20</th>\n",
              "      <th>T2_20</th>\n",
              "      <th>GOLD_Lesions</th>\n",
              "      <th>y</th>\n",
              "      <th>x</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.143692</td>\n",
              "      <td>1.586219</td>\n",
              "      <td>-0.799859</td>\n",
              "      <td>1.634467</td>\n",
              "      <td>0.437568</td>\n",
              "      <td>0.823800</td>\n",
              "      <td>-0.002059</td>\n",
              "      <td>0.573663</td>\n",
              "      <td>0.279832</td>\n",
              "      <td>0.548341</td>\n",
              "      <td>0.219136</td>\n",
              "      <td>0.298662</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.466353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.652552</td>\n",
              "      <td>1.766672</td>\n",
              "      <td>-1.250992</td>\n",
              "      <td>0.921230</td>\n",
              "      <td>0.663037</td>\n",
              "      <td>0.880250</td>\n",
              "      <td>-0.422060</td>\n",
              "      <td>0.542597</td>\n",
              "      <td>0.422182</td>\n",
              "      <td>0.549711</td>\n",
              "      <td>0.061573</td>\n",
              "      <td>0.280972</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.534121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.036099</td>\n",
              "      <td>0.262042</td>\n",
              "      <td>-0.858565</td>\n",
              "      <td>-0.058211</td>\n",
              "      <td>-0.044280</td>\n",
              "      <td>-0.308569</td>\n",
              "      <td>0.014766</td>\n",
              "      <td>-0.256075</td>\n",
              "      <td>-0.136532</td>\n",
              "      <td>-0.350905</td>\n",
              "      <td>0.020673</td>\n",
              "      <td>-0.259914</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.746050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.037692</td>\n",
              "      <td>0.011104</td>\n",
              "      <td>-1.228796</td>\n",
              "      <td>-0.470222</td>\n",
              "      <td>-0.013971</td>\n",
              "      <td>-0.000498</td>\n",
              "      <td>-0.395575</td>\n",
              "      <td>-0.221900</td>\n",
              "      <td>0.000807</td>\n",
              "      <td>-0.003085</td>\n",
              "      <td>-0.193249</td>\n",
              "      <td>-0.139284</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.284565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.580589</td>\n",
              "      <td>1.730152</td>\n",
              "      <td>-0.860949</td>\n",
              "      <td>1.245609</td>\n",
              "      <td>0.617957</td>\n",
              "      <td>0.866352</td>\n",
              "      <td>-0.099919</td>\n",
              "      <td>0.384261</td>\n",
              "      <td>0.391133</td>\n",
              "      <td>0.608826</td>\n",
              "      <td>0.071648</td>\n",
              "      <td>0.340601</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.958099</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-494f9b53-9de2-460f-a737-ed74bc1716ca')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-494f9b53-9de2-460f-a737-ed74bc1716ca button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-494f9b53-9de2-460f-a737-ed74bc1716ca');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fit = smf.logit('y ~ x', data = dat).fit()\n",
        "fit.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "DgGt_w-CH9L_",
        "outputId": "7230d7b3-5b01-4a35-e362-8fadb44b2c75"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.687421\n",
            "         Iterations 4\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                           Logit Regression Results                           \n",
              "==============================================================================\n",
              "Dep. Variable:                      y   No. Observations:                  100\n",
              "Model:                          Logit   Df Residuals:                       98\n",
              "Method:                           MLE   Df Model:                            1\n",
              "Date:                Mon, 03 Oct 2022   Pseudo R-squ.:                0.008262\n",
              "Time:                        20:48:20   Log-Likelihood:                -68.742\n",
              "converged:                       True   LL-Null:                       -69.315\n",
              "Covariance Type:            nonrobust   LLR p-value:                    0.2845\n",
              "==============================================================================\n",
              "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "Intercept      0.0005      0.201      0.002      0.998      -0.394       0.395\n",
              "x              0.2159      0.204      1.061      0.289      -0.183       0.615\n",
              "==============================================================================\n",
              "\"\"\""
            ],
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Logit Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>           <td>y</td>        <th>  No. Observations:  </th>  <td>   100</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>    98</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     1</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>            <td>Mon, 03 Oct 2022</td> <th>  Pseudo R-squ.:     </th> <td>0.008262</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                <td>20:48:20</td>     <th>  Log-Likelihood:    </th> <td> -68.742</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -69.315</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>  <td>0.2845</td> \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Intercept</th> <td>    0.0005</td> <td>    0.201</td> <td>    0.002</td> <td> 0.998</td> <td>   -0.394</td> <td>    0.395</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x</th>         <td>    0.2159</td> <td>    0.204</td> <td>    1.061</td> <td> 0.289</td> <td>   -0.183</td> <td>    0.615</td>\n",
              "</tr>\n",
              "</table>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yhat = 1 / (1 + np.exp(-fit.fittedvalues))\n",
        "n = dat.shape[0]\n",
        "\n",
        "## Get the y and x from \n",
        "xtraining = torch.from_numpy(dat['x'].values)\n",
        "ytraining = torch.from_numpy(dat['y'].values)\n",
        "\n",
        "## PT wants floats\n",
        "xtraining = xtraining.float()\n",
        "ytraining = ytraining.float()\n",
        "\n",
        "## Dimension is 1xn not nx1\n",
        "## squeeze the second dimension\n",
        "xtraining = xtraining.unsqueeze(1)\n",
        "ytraining = ytraining.unsqueeze(1)\n",
        "\n",
        "## Show that everything is the right size\n",
        "[xtraining.shape, \n",
        " ytraining.shape,\n",
        " [n, 1]\n",
        " ]\n",
        "\n",
        "class LogisticRegression(torch.nn.Module):\n",
        "     def __init__(self):\n",
        "        super(LogisticRegression, self).__init__()\n",
        "        self.linear = torch.nn.Linear(1, 1, bias = True)\n",
        "     def forward(self, x):\n",
        "        y_pred = torch.sigmoid(self.linear(x))\n",
        "        return y_pred\n",
        "\n",
        "## Then the model is simply  \n",
        "model = LogisticRegression()\n",
        "\n",
        "## MSE is the loss function\n",
        "loss_fn = torch.nn.BCELoss()  \n",
        "\n",
        "## Set the optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=5e-3)\n",
        "\n",
        "## Loop over iterations\n",
        "for t in range(100000):\n",
        "\n",
        "  ## Forward propagation\n",
        "  y_pred = model(xtraining)\n",
        "\n",
        "  ## the loss for this interation\n",
        "  loss = loss_fn(y_pred, ytraining)\n",
        "\n",
        "  #print(t, loss.item() / n)\n",
        "\n",
        "  ## Zero out the gradients before adding them up \n",
        "  optimizer.zero_grad()\n",
        "  \n",
        "  ## Backprop\n",
        "  loss.backward()\n",
        "  \n",
        "  ## Optimization step\n",
        "  optimizer.step()\n",
        "\n",
        "ytest = model(xtraining)\n",
        "ytest = ytest.detach().numpy().reshape(-1)\n",
        "plt.plot(yhat, ytest,  \".\")\n",
        "plt.plot([0.4, 0.7], [0.4, 0.7], linewidth=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "uv6d3yeGIbfv",
        "outputId": "28b07e24-44b1-46a6-880d-6b9ccedb27a9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f55fa5adb50>]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters():  \n",
        "  print(param.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8ulCwymPpAp",
        "outputId": "82b94c63-84c3-4a78-9a63-bd4ddcdcdbd3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2159]])\n",
            "tensor([0.0005])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Fit a pytorch neural network with two hidden layers on the diamond dataset from the previous project predicting price. Evaluate your predictions on held out test set data."
      ],
      "metadata": {
        "id": "3Ms0I8a608hY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diamond = pd.read_csv(\"https://raw.githubusercontent.com/tidyverse/ggplot2/master/data-raw/diamonds.csv\")\n",
        "y = torch.from_numpy(diamond[['price']].values)\n",
        "dnew = diamond.drop(['table', 'depth', 'price','x','y','z'], axis=1)\n",
        "x = pd.get_dummies(dnew)\n"
      ],
      "metadata": {
        "id": "2RO5gyXoM3tL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainFraction = .75\n",
        "\n",
        "sample = np.random.uniform(size = len(y)) < trainFraction\n",
        "trainingDat = diamond[sample]\n",
        "testingDat = diamond[~sample]\n",
        "\n",
        "x = torch.tensor(x.values)\n",
        "y = torch.tensor(y)\n",
        "\n",
        "xtraining = x[sample]\n",
        "xtesting = x[~sample]\n",
        "ytraining = y[sample]\n",
        "ytesting = y[~sample]\n",
        "\n",
        "[\n",
        " xtraining.size(),\n",
        " ytraining.size(),\n",
        " xtesting.size(),\n",
        " ytesting.size(),\n",
        "]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKvLbPrwS_R1",
        "outputId": "56ff941b-2e64-402d-b676-4fbfcf294e42"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[torch.Size([40600, 21]),\n",
              " torch.Size([40600, 1]),\n",
              " torch.Size([13340, 21]),\n",
              " torch.Size([13340, 1])]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xtraining = xtraining.float()\n",
        "xtesting = xtesting.float()\n",
        "ytraining = ytraining.float().unsqueeze(1)\n",
        "ytesting = ytesting.float().unsqueeze(1)\n",
        "\n",
        "H1 = 6\n",
        "H2 = 3\n",
        "\n",
        "## Number of predictors\n",
        "D_in = xtraining.shape[1]\n",
        "D_out = 1\n",
        "\n",
        "model = torch.nn.Sequential(\n",
        "    torch.nn.Linear(D_in, H1),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(H1, H2),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(H2, D_out)\n",
        ")\n",
        "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
        "\n",
        "learning_rate = 1e-10\n",
        "for t in range(1000):\n",
        "    y_pred = model(xtraining)\n",
        "    loss = loss_fn(y_pred, ytraining)\n",
        "    if t % 100 == 0:\n",
        "        print(t, loss.item())\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "    with torch.no_grad():\n",
        "        for param in model.parameters():\n",
        "            param -= learning_rate * param.grad\n",
        "\n",
        "ytesting_pred = model(xtesting)\n",
        "a = ytesting_pred.detach().numpy()\n",
        "\n",
        "plt.scatter(a[:,0], ytesting[:,0], \".\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "6dGrpTYxX1UN",
        "outputId": "aeb97dd3-3094-43c9-eb2b-b487da4ad2db"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:530: UserWarning: Using a target size (torch.Size([40600, 1, 1])) that is different to the input size (torch.Size([40600, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 5.133252999879066e+16\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-0714f0445a48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title('Fitted vs Test Data')\n",
        "plt.xlabel('Fitted Values')\n",
        "plt.ylabel('Test Data')\n"
      ],
      "metadata": {
        "id": "2VgzJ-jemO0H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}